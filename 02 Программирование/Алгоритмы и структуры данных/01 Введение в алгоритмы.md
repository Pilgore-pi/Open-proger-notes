
**Алгоритм** — это четкая последовательность действий (шагов, операций). При одних и тех же входных данных результат всегда один и тот же.

Алгоритмы бывают нескольких типов:

- **Линейный:** за первым шагов всегда следует второй, за которым следует третий и т.д.
- **Ветвящийся:** В алгоритме может выполяться как шаг А, так и шаг Б, в зависимости от некоторого условия
- **Цикличный:** Алгоритм выполняет один и тот же шаг многократно, до тех пор, пока условие завершения не выполнится
- **Составной:** Алгоритм, содержащий в себе другие несколько алгоритмов

## Оценка сложности алогоритмов

Сложность алгоритмов оценивается, в основном, по двум критериям:

- Занимаемое время
- Занимаемая память

**В чем оценивается сложность алгоритмов?** — в зависимости (функции) времени или памяти от количества данных

Скорость выполнения одного и того же алгоритма над одними и теми же данными, но на разных устройствах может сильно отличаться, поэтому оценивать выполнение алгоритма в абсолютных значениях, например в секундах, бессмысленно.

Количество операций и используемой памяти в алгоритме в большинстве случаев зависит от данных, над которыми совершается алгоритм, поэтому, обычно, нет возможности найти функцию, которая бы представляла собой точную зависимость времени от данных.

Поэтому, вместо конкретных функций времени от данных используются крайние значения, за которые функция точно не должна выходить.

Для дальнейших рассуждений, введем функцию **$f(n)$**, которая представляет собой **фактическое время** алгоритма, зависящее от **количества элементов** данных $n$. Функцию $f(n)$ можно представить как отобржение:  **`Время` $\rightarrow$ `количество_элементов`** $(Y \rightarrow X)$ или как функцию: **`Время(количество_элементов)`** $Y(X)$

Оценки сложности алгоритмов основаны на анализе максимального или минимального количества времени или памяти, необходимого, для данного алгоритма. При этом не может быть такого, что фактическое занимаемое время или память выходят за границы оценок алгоритмов (если эти оценки верные)

### О-большое

**O-большое** используется для обозначения **верхней границы** временной сложности алгоритма. Это означает, что оно описывает наихудший (самый пессимистичный) случай выполнения алгоритма.

Существует несколько типов функций, описывающих сложность алгоритма:

Пусть $t$ — время, а $n$ — количество шагов алгоритма

| Функция         | Тип                     | Описание                                                                                          |
| --------------- | ----------------------- | ------------------------------------------------------------------------------------------------- |
| $O(1)$          | константная             | $t = c$. Алгоритм выполняется за одно и то же время, и никак не зависит от размера входных данных |
| $O(\log_2 n)$   | логарифмическая         | $t \sim \log_2 n$ (время пропорционально логарифму от числа шагов)                                |
| $O(\sqrt n)$    | сублинейная             | $t \sim \sqrt n$                                                                                  |
| $O(n)$          | линейная                | $t \sim n$                                                                                        |
| $O(n \log_2 n)$ | линейно-логарифмическая | $t \sim n \log_2 n$                                                                               |
| $O(n^2)$        | квадратичная            | $t \sim n^2$                                                                                      |
| $O(n^n)$        | степенная               | $t \sim n^n$                                                                                      |
| $O(2^n)$        | экспоненциальная        | $t \sim 2^n$                                                                                      |
| $O(n!)$         | факториальная           | $t \sim 1 \cdot 2 \cdot 3\cdot\ \ ...\ \ \cdot (n-1) \cdot n$                                     |
| $O(g(n))$       | сложная                 | одна из перечисленных выше функций или их комбинация                                              |

>Константы, при оценке алгоритма, отбрасываются, так как не оказывают существенного влияния на оценку. Поэтому, напрмер $O(1 + n + 1) = O(n);\ \ O(2n) = O(100n) = O(n)$

Если алгоритм ожидает на вход не один параметр, а несколько, то каждый из них нужно будет учитывать.

##### Пример 1

Например, есть алгоритм $A(n, k)$, зависящий от двух аргументов:

```csharp
Algorithm(n, k)
{
    sum = n + k; // какая-то операция (сложность 1)
    
    for(int i = 0; i < n; i++)
    {
        ... // операции в цикле (сложность N)
    }
    for(int i = 0; i < k; i++)
    {
        ... // сложность K
    }
    
    sub = n - k; // сложность 1
}
```

Итого, фактическая сложность такого алгоритма: $O(1 + n + k + 1) = O(n + k)$

##### Пример 2

```csharp
AlgorithmInner(n)
{
    for(int i = 0; i < n; i++)
    {
        ... // сложность N
    }
}

AlgorithmOuter(n)
{
    for(int i = 0; i < n; i++)
    {
        AlgorithmInner(n); // сложность N * N
    }
    
    for(int i = 0; i < n; i++)
    {
        ... // сложность N
    }
}
```

Сложность алгоритма `AlgorithmOuter(n)` $= O(n^2 + n) = O(n^2)$

#### Сложность по памяти

Допустим алгоритм $A(n)$ представляет собой обычный цикл, выполняющийся $n$ раз.
Такой алгоритм будет иметь:

- **сложность по времени** $O(n)$
- **сложность по памяти** $O(1)$, так как испольуется константное количество переменных (итератор $i$ и, возможно несколько других переменных); количество выделяемой памяти всегда будет одним и тем же

Рекурсивный алгоритм, реализованный через самовызов некоторой функции будет накапливать кадры в стековой оперативной памяти при увеличении глубины рекурсии, поэтому простейший рекурсивный алгоритм будет иметь **сложность по памяти** $O(n)$

>Учитывается только самая старшая степень

>Формально, функция $f(n) = O(g(n))$, где $g(n)$ — сложность алгоритма, если существуют константы $c>0$ и $n_0>0$ такие, что для всех $n≥n_0$​ выполняется неравенство:

$$f(n)≤c⋅g(n)$$
(Я сам не понимаю, что это значит)

### $\Omega$-большое (Омега-большое)

**Омега-большое** обозначает **нижнюю границу** временной сложности алгоритма. Это позволяет оценить лучший (самый оптимистичный) случай выполнения алгоритма.

>Функция $f(n) = \Omega(g(n))$, если существуют константы $c>0$ и $n_0>0$​ такие, что для всех $n≥n_0$​ выполняется неравенство:

$$f(n)≥c⋅g(n)$$

Пример: Если алгоритм имеет временную сложность Ω(n), это означает, что время выполнения алгоритма в лучшем случае не будет меньше некоторой константы, умноженной на размер входных данных.

### $\Theta$-большое (Тета-большое)

**Тета-большое** обозначает **точную оценку** временной сложности алгоритма. Это значит, что функция ограничена как сверху, так и снизу.

>Функция $f(n) = \Theta(g(n))$, если существуют положительные константы $c_1>0,\ c_2>0​$ и $n_0>0​$ такие, что для всех $n≥n_0$​ выполняется:

$$c_1⋅g(n)≤f(n)≤c_2⋅g(n)$$

Пример: Если алгоритм имеет временную сложность $\Theta(n \log_2 ⁡n)$, это означает, что время выполнения алгоритма растет пропорционально nlog⁡nnlogn, как в худшем, так и в лучшем случае.

Источники:

* [Perplexity](https://www.perplexity.ai/search/kakie-sushchestvuiut-raznovidn-S6232lpFRqWOlty3TImDcg)
* [Alek OS]()

#Algorithms